{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic python and ML Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "# reading images using OpenCV\n",
    "import cv2\n",
    "\n",
    "# matplotlib & others for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# torchvision libraries\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# for images\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "root = pathlib.Path(\"data\") / \"car\" / 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def tensorprint(tensor):\n",
    "    print(\"Shape: \" , tensor.shape, \" , Dimension: \", tensor.ndim , \" \\nDtype: \", tensor.dtype, \" , Device: \", tensor.device)\n",
    "    print(\"Max: \", tensor.amax(),f'[{tensor.argmax()}]', \" , Min: \", tensor.amin(),f'[{tensor.argmin()}]')\n",
    "    #print(tensor ,'\\n')\n",
    "\n",
    "def torch_rng():\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "def walk_through_dir(dir_path):\n",
    "    \"\"\"Walks Through dir_path returning its contents.\"\"\"\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f\"directories: {len(dirnames)} | images: {len(filenames)} -> {dirpath}\")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "def show_bbox(image_path, label):\n",
    "    image = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    x1, y1, x2, y2 = label[0], label[1], label[2], label[3]\n",
    "    draw.rectangle((x1,y1,x2,y2), outline = (255,0,0), width = 5)\n",
    "    image.show()\n",
    "\n",
    "def OD_train_step(model, optimizer, data_loader, device = device):\n",
    "    model.train()\n",
    "    train_loss_list = []\n",
    "    c = 0\n",
    "\n",
    "    for images , targets in data_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "        train_loss_list.append(loss_value)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        c+=1\n",
    "\n",
    "        if c % 4 == 0:\n",
    "            print(f\"Training loss: {loss_value}\")\n",
    "\n",
    "    return train_loss_list\n",
    "\n",
    "def OD_test_step(model, optimizer, data_loader, device = device):\n",
    "    val_loss_list = []\n",
    "    c= 0\n",
    "\n",
    "    for images, targets in data_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            loss_dict = model(images, targets)\n",
    "            \n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            loss_value = losses.item()\n",
    "            val_loss_list.append(loss_value)\n",
    "            c+=1\n",
    "\n",
    "            if c % 4 == 0:\n",
    "                print(f\"Testing loss: {loss_value}\")\n",
    "\n",
    "        return val_loss_list\n",
    "\n",
    "def get_transform(img, target):\n",
    "    train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),                        \n",
    "    ])\n",
    "\n",
    "    return train_transform(img), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup \n",
    "train_dir = root / 'training_images'\n",
    "test_dir = root / 'testing_images'\n",
    "train_label_dir = root / 'train_solution_bounding_boxes (1).csv'\n",
    "\n",
    "train_image_list = sorted(os.listdir(train_dir))\n",
    "test_image_list = sorted(os.listdir(test_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=640x640>,\n",
       " {'boxes': tensor([281.2590, 187.0351, 327.7279, 223.2255]),\n",
       "  'labels': tensor(1),\n",
       "  'area': tensor(1681.7317),\n",
       "  'iscrowd': tensor([0, 0, 0, 0])})"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset \n",
    "\n",
    "class CarDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,image, label, transforms) -> None:\n",
    "        self.image = image\n",
    "        self.label = label\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.imgs = os.listdir(image)\n",
    "        self.labels = pd.read_csv(label)\n",
    "\n",
    "        self.label_image_check = self.labels[self.labels['image'].isin(self.imgs)]\n",
    "        self.labels_name_list = self.label_image_check['image'].tolist()\n",
    "\n",
    "        self.imgs = [i for i in self.labels_name_list if i in self.imgs]\n",
    "\n",
    "        check = True if len(e.imgs) == len(e.labels) else False\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        W, H = 640, 640\n",
    "        img_path = os.path.join(self.image , self.imgs[idx])\n",
    "        labels = self.labels[self.labels['image'] == self.imgs[idx]]\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((W,H), Image.LANCZOS)\n",
    "        \n",
    "        boxes = labels.drop(columns=['image'], axis=1).values.tolist()[0]\n",
    "        labels = 1\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        area = ((boxes[3] - boxes[1]) * (boxes[2] - boxes[0]))\n",
    "        iscrowd = torch.zeros(boxes.shape[0], dtype = torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['area'] = area\n",
    "        target['iscrowd'] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "\n",
    "        return img, target\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "e = CarDataset(train_dir, train_label_dir, None)\n",
    "e[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data = CarDataset(train_dir, train_label_dir,get_transform)                             \n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_data, \n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                shuffle=True,\n",
    "                                collate_fn=collate_fn)\n",
    "\n",
    "                                \n",
    "img, target = next(iter(train_dataloader))\n",
    "images = list(image.to(device) for image in img)\n",
    "targets = [{k : v.to(device) for k , v in t.items()} for t in target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8174828e92d9e3a5ca64f417386608000b35cfcceb5edd6aed1e8771c000af37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
