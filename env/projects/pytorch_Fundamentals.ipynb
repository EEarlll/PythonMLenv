{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def tensorprint(tensor):\n",
    "    print(\"Shape: \" , tensor.shape, \" , Dimension: \", tensor.ndim , \" \\nDtype: \", tensor.dtype, \" , Device: \", tensor.device)\n",
    "    print(\"Max: \", tensor.amax(),f'[{tensor.argmax()}]', \" , Min: \", tensor.amin(),f'[{tensor.argmin()}]')\n",
    "    print(tensor ,'\\n')\n",
    "\n",
    "def plot_linear_predictions(train_data, train_label, \n",
    "                    test_data, test_labels, \n",
    "                    predictions = None):\n",
    "                    plt.figure(figsize=(8,4))\n",
    "                    plt.scatter(train_data,train_label, c=\"g\", s=2, label=\"Training data\")\n",
    "                    plt.scatter(test_data, test_labels, c=\"r\", s=2, label =\"Testing data\")\n",
    "                    if predictions != None:\n",
    "                        plt.scatter(test_data, predictions, c=\"b\", s=2, label = \"Predictions\" )\n",
    "                    plt.legend(prop= {\"size\": 10})\n",
    "\n",
    "def plot_curves(epoch_count, loss_values, test_lost_values):\n",
    "    plt.plot(epoch_count, loss_values, label=\"Train loss\")\n",
    "    plt.plot(epoch_count,test_lost_values, label=\"Test loss\")\n",
    "    plt.title(\"Training and test loss curves\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "                    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalar , vector, matrix\n",
    "# scalar\n",
    "scalar = torch.tensor(69)\n",
    "tensorprint(scalar)\n",
    "\n",
    "# vector\n",
    "vector = torch.tensor([6,9])\n",
    "tensorprint(vector)\n",
    "\n",
    "# matrix\n",
    "matrix = torch.tensor([ [2,4],\n",
    "                        [5,9]])\n",
    "tensorprint(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tensor\n",
    "tensor = torch.tensor([[[1,2,3],\n",
    "                        [4,5,6],\n",
    "                        [7,8,9]]],\n",
    "                        dtype = torch.float32,\n",
    "                        device = \"cpu\",\n",
    "                        requires_grad=False)\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)          # reproduce seed once\n",
    "tensor_A = torch.rand(1,3,3)\n",
    "tensor_B = torch.rand(1,3,3)\n",
    "tensor_gA = tensor_A.to(device)         # change to gpu if available\n",
    "\n",
    "int32_tensor = tensor.type(torch.int32)\n",
    "random_image_tensor = torch.rand(size=(224,224,3))\n",
    "range_zeros = torch.zeros_like(random_image_tensor)\n",
    "zero_tensor = torch.zeros(3,3,5)\n",
    "one_tensor = torch.ones(3,3,5)\n",
    "permuted_tensor = tensor_A.permute(1,2,0)\n",
    "range_tensor = torch.arange(start = 0, end = 15, step = 1)\n",
    "numpy_a = np.arange(1.0,10.0)\n",
    "tensor_nA = torch.from_numpy(numpy_a).type(torch.float32)\n",
    "numpy_A = tensor_A.numpy()\n",
    "\n",
    "# tensorprint(tensor)\n",
    "# tensorprint(tensor_A)\n",
    "# tensorprint(tensor_B)\n",
    "tensorprint(permuted_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulating tensors\n",
    "basic_operations_tn = torch.add(torch.mul(tensor, 11), 2)\n",
    "element_mul_tn = torch.mul(tensor, basic_operations_tn)\n",
    "tensor_B_transpose = tensor_B.mT\n",
    "tensor_A_type_change = tensor_A.type(torch.int32)\n",
    "tensor_A_reshaped = tensor.reshape(1,9)                 # not same memory as tensor_A\n",
    "tensor_A_view = tensor_A.view(9,1)                      # same memory as tensor_A\n",
    "tensor_A_stack = torch.stack([tensor_A, tensor],dim=1)  # stack tensor to each other hstack/vstack\n",
    "tensor_A_squeeze = torch.squeeze(tensor_A_reshaped)     # remove single dimension [1,1,9] = [9]\n",
    "tensor_A_unsqueeze = torch.unsqueeze(tensor_A_squeeze, dim=0)\n",
    "tensor_A_permute = torch.permute(tensor_A, (2,1,0))\n",
    "\n",
    "# tensor aggregation (min,max,sum, etc)\n",
    "tensor_Amax = tensor_A.max()\n",
    "tensor_Amin = tensor_A.min()\n",
    "tensor_Asum = torch.sum(tensor_A)\n",
    "tensor_Amean = torch.mean(tensor_A)\n",
    "tensor_argmin = tensor_A.argmin()\n",
    "tensor_argmax = tensor_A.argmax()\n",
    "\n",
    "# indexing\n",
    "tensor_index = [tensor[:, 0], tensor[:, 1], tensor[:,:,0], \n",
    "                tensor[:,:,1], tensor[:,1,1], \n",
    "                ]\n",
    "for i in tensor_index:\n",
    "    tensorprint(i)\n",
    "# matrix multiplication = xrow * ycolumn \n",
    "matrix_matmul_tn = torch.matmul(tensor, tensor_A)\n",
    "tensorprint(tensor_A)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating parameters and data\n",
    "weight = 0.9\n",
    "bias = 0.4  \n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.01\n",
    "\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train/test split\n",
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "X_train, y_train = X_train.to(device) , y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "plot_linear_predictions(X_train.cpu(),y_train.cpu(),X_test.cpu(),y_test.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize model parameters using built in pytorch\n",
    "        self.linear_layer = nn.Linear(in_features=1, out_features=1)\n",
    "    \n",
    "        # Initialize model parameters YOURSELF\n",
    "        # self.weights = nn.Parameter(torch.randn(1,requires_grad= True, \n",
    "        #                                         dtype=torch.float))\n",
    "        # self.bias = nn.Parameter(torch.randn(1,requires_grad = True,\n",
    "        #                                         dtype=torch.float))\n",
    "\n",
    "    \n",
    "    # forward() defines computation in model\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.linear_layer(x)\n",
    "\n",
    "        # computation when you initialize YOURSELF\n",
    "        # return self.weights * x + self.bias\n",
    "\n",
    "torch.manual_seed(69)\n",
    "model_0 = LinearRegressionModel()\n",
    "model_0.to(device)\n",
    "parameters = model_0.state_dict()\n",
    "with torch.inference_mode():                          # disables grad\n",
    "    y_preds_wt= model_0(X_test)\n",
    "plot_linear_predictions(X_train.cpu(),y_train.cpu(),X_test.cpu(),y_test.cpu(), y_preds_wt.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a model\n",
    "# Loss functions & Optimizer\n",
    "torch.manual_seed(69)\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(params = model_0.parameters(),\n",
    "                            lr= 0.001)\n",
    "\n",
    "epochs= 1000\n",
    "epoch_count = []\n",
    "loss_values = []\n",
    "test_lost_values = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_0.train()                             # train mode\n",
    "    y_pred = model_0(X_train)                   # make predictions\n",
    "\n",
    "    loss = loss_fn(y_pred, y_train)             # calculate loss w/ pred & train\n",
    "    optimizer.zero_grad()                       # set to 0 the acuumulate\n",
    "    loss.backward()                             # backpropogation\n",
    "    optimizer.step()                            # gradient descent +1 accumulate\n",
    "\n",
    "    model_0.eval()                              # tunrs settings not needed\n",
    "    if epoch % 200 == 0:\n",
    "        with torch.inference_mode():                          \n",
    "            y_prednew = model_0(X_test)\n",
    "            test_lost = loss_fn(y_prednew, y_test)\n",
    "            plot_linear_predictions(X_train.cpu(),y_train.cpu(),X_test.cpu(),y_test.cpu(),y_prednew.cpu())    \n",
    "        epoch_count.append(epoch)\n",
    "        loss_values.append(loss.cpu())\n",
    "        test_lost_values.append(test_lost.cpu())\n",
    "\n",
    "converted_lossnp = np.array(torch.tensor(loss_values).numpy())                 \n",
    "\n",
    "print(loss)\n",
    "print(weight, bias, '\\n', parameters)\n",
    "plot_curves(epoch_count,converted_lossnp,test_lost_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "MODEL_PATH = Path(\"Models\")\n",
    "MODEL_PATH.mkdir(parents= True, exist_ok =True)\n",
    "MODEL_NAME = \"01_LinearRegression_0.pt\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "torch.save(model_0.state_dict(), MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model \n",
    "lmodel_0 = LinearRegressionModel()\n",
    "lmodel_0.to(device)\n",
    "lmodel_0.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "with torch.inference_mode():\n",
    "    lmodel_0_preds = lmodel_0(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8174828e92d9e3a5ca64f417386608000b35cfcceb5edd6aed1e8771c000af37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
